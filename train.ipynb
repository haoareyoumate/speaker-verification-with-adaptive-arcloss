{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "from dataset import create_all_file_list, create_dataset\n",
    "from lossfunction import ArcLoss, AdaptiveArcLoss, AdaptiveArcLossVer2\n",
    "from metrics import AverageAngle, EqualErrorRate\n",
    "from model import EmbedModel, CosineSimilarityModel, MyLRSchedule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell for the first time run this notebook\n",
    "\n",
    "#all_file = create_all_file_list()\n",
    "#with open('file_list/all_file_list.pkl', 'wb') as f:\n",
    "#    pickle.dump(all_file, f)\n",
    "\n",
    "#all_file_test = create_all_file_list('/kaggle/input/darpa-timit-acousticphonetic-continuous-speech/data/TEST/*/*')\n",
    "#with open('file_list/all_file_test_list.pkl', 'wb') as f:\n",
    "#    pickle.dump(all_file_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('file_list/all_file_list.pkl', 'rb') as f:\n",
    "    all_file_list = pickle.load(f)\n",
    "with open('file_list/all_file_test_list.pkl', 'rb') as f:\n",
    "    all_file_test_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(None,))\n",
    "embed_model = EmbedModel()\n",
    "classify_model = CosineSimilarityModel()\n",
    "embedding_vector = embed_model(inputs)\n",
    "outputs = classify_model(embedding_vector)\n",
    "combined_model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "ds_train = create_dataset(batch_size=32)\n",
    "\n",
    "lr_schedule = MyLRSchedule()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "margin_ratio = 0.3\n",
    "initial_margin = 0.27\n",
    "\n",
    "adaptive_arcloss = AdaptiveArcLossVer2(margin_ratio=margin_ratio, initial_margin=initial_margin)\n",
    "\n",
    "angle_metric = AverageAngle()\n",
    "\n",
    "log_dir = r\"logs300/\" + 'adaptivearcloss_mr' + str(margin_ratio).replace('.','') + '_i_' + str(initial_margin).replace('.','') + datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "combined_model.compile(optimizer=optimizer, loss=adaptive_arcloss, metrics=[angle_metric,'acc'])\n",
    "combined_model.fit(ds_train, epochs=300, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_config = adaptive_arcloss.get_config()\n",
    "print(loss_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = create_dataset(test=True)\n",
    "eer_metric = EqualErrorRate(ds_test)\n",
    "print(eer_metric.calculate_eer(embed_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model.save_weights(r\"weight/embed_model.weights.h5\")\n",
    "classify_model.save_weights(r\"weight/classify_model.weights.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
